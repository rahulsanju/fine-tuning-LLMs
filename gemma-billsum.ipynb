{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3343571,"sourceType":"datasetVersion","datasetId":1987515},{"sourceId":11382,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":8318}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-29T23:52:15.308157Z","iopub.execute_input":"2024-03-29T23:52:15.308529Z","iopub.status.idle":"2024-03-29T23:52:15.325546Z","shell.execute_reply.started":"2024-03-29T23:52:15.308502Z","shell.execute_reply":"2024-03-29T23:52:15.324594Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/billsum-processed-train/catest_processed.csv\n/kaggle/input/billsum-processed-train/ustrain_processed.csv\n/kaggle/input/billsum-processed-train/ustest_processed.csv\n/kaggle/input/gemma/transformers/2b-it/2/model.safetensors.index.json\n/kaggle/input/gemma/transformers/2b-it/2/gemma-2b-it.gguf\n/kaggle/input/gemma/transformers/2b-it/2/config.json\n/kaggle/input/gemma/transformers/2b-it/2/model-00001-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b-it/2/model-00002-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b-it/2/tokenizer.json\n/kaggle/input/gemma/transformers/2b-it/2/tokenizer_config.json\n/kaggle/input/gemma/transformers/2b-it/2/special_tokens_map.json\n/kaggle/input/gemma/transformers/2b-it/2/.gitattributes\n/kaggle/input/gemma/transformers/2b-it/2/tokenizer.model\n/kaggle/input/gemma/transformers/2b-it/2/generation_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install -U -q transformers langchain peft bitsandbytes trl datasets==2.16.0 notebook accelerate evaluate rouge","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:52:24.136717Z","iopub.execute_input":"2024-03-29T23:52:24.137385Z","iopub.status.idle":"2024-03-29T23:53:05.967891Z","shell.execute_reply.started":"2024-03-29T23:52:24.137353Z","shell.execute_reply":"2024-03-29T23:53:05.966893Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ns3fs 2024.3.0 requires fsspec==2024.3.0, but you have fsspec 2023.10.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline, set_seed\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom accelerate.utils import release_memory\nimport torch\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom datasets import Dataset\nfrom trl import SFTTrainer\nfrom peft import LoraConfig, PeftModel\nimport pandas as pd\nfrom langchain.chains.summarize import load_summarize_chain\nfrom langchain.text_splitter import CharacterTextSplitter, HTMLHeaderTextSplitter\nfrom langchain.prompts import PromptTemplate\nfrom langchain.docstore.document import Document\nfrom langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\nimport evaluate\nimport transformers\nfrom langchain.llms.base import LLM\nfrom typing import Any\nimport warnings\nimport gc\nimport random\nimport numpy as np\n\nwarnings.filterwarnings('ignore')\n\n# Set seed for reproducibility\nset_seed(42)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n# Logging in HF\nlogin(token = 'HF_TOKEN')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:53:22.675667Z","iopub.execute_input":"2024-03-29T23:53:22.676473Z","iopub.status.idle":"2024-03-29T23:53:41.947866Z","shell.execute_reply.started":"2024-03-29T23:53:22.676439Z","shell.execute_reply":"2024-03-29T23:53:41.946906Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-03-29 23:53:30.046648: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-29 23:53:30.046762: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-29 23:53:30.173055: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"training = pd.read_csv('/kaggle/input/billsum-processed-train/ustrain_processed.csv')[['clean_text','summary']]\ntraining.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:56:02.380206Z","iopub.execute_input":"2024-03-29T23:56:02.380985Z","iopub.status.idle":"2024-03-29T23:56:03.962416Z","shell.execute_reply.started":"2024-03-29T23:56:02.380953Z","shell.execute_reply":"2024-03-29T23:56:03.961520Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                          clean_text  \\\n0  SECTIONHEADER SHORT TITLE. This Act may be cit...   \n1  SECTIONHEADER SHORT TITLE. This Act may be cit...   \n2  SECTIONHEADER SHORT TITLE. This Act may be cit...   \n3  SECTIONHEADER SHORT TITLE. This Act may be cit...   \n4  SECTIONHEADER SHORT TITLE. This Act may be cit...   \n\n                                             summary  \n0  Border Hospital Survival and Illegal Immigrant...  \n1  Farm to School Improvements Act of 2010 - Amen...  \n2  Persian Gulf War Illness Compensation Act of 2...  \n3  Medicare Part D Outreach and Enrollment Enhanc...  \n4  Seniors' Retirement Recovery Act of 2002 - Ame...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_text</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SECTIONHEADER SHORT TITLE. This Act may be cit...</td>\n      <td>Border Hospital Survival and Illegal Immigrant...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SECTIONHEADER SHORT TITLE. This Act may be cit...</td>\n      <td>Farm to School Improvements Act of 2010 - Amen...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SECTIONHEADER SHORT TITLE. This Act may be cit...</td>\n      <td>Persian Gulf War Illness Compensation Act of 2...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SECTIONHEADER SHORT TITLE. This Act may be cit...</td>\n      <td>Medicare Part D Outreach and Enrollment Enhanc...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SECTIONHEADER SHORT TITLE. This Act may be cit...</td>\n      <td>Seniors' Retirement Recovery Act of 2002 - Ame...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model = \"/kaggle/input/gemma/transformers/2b-it/2\"\n\nlora_config = LoraConfig(\n    r=6,\n    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    task_type=\"CAUSAL_LM\",\n)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model)\ntokenizer.padding_side = \"right\" # Fixing overflow issue ref: source code\nmodel = AutoModelForCausalLM.from_pretrained(model, device_map=\"auto\", quantization_config=bnb_config)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:57:13.311761Z","iopub.execute_input":"2024-03-29T23:57:13.312411Z","iopub.status.idle":"2024-03-29T23:57:45.363493Z","shell.execute_reply.started":"2024-03-29T23:57:13.312379Z","shell.execute_reply":"2024-03-29T23:57:45.362726Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Gemma's activation function should be approximate GeLU and not exact GeLU.\nChanging the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52a284432f7a450b849f96366b15a272"}},"metadata":{}}]},{"cell_type":"code","source":"training = training.head(10000)\ntrain_data = Dataset.from_pandas(training)\n\ntest_df = pd.read_csv('/kaggle/input/billsum-processed-train/catest_processed.csv')[['clean_text','summary']]\ntesting_data = Dataset.from_pandas(test_df.head(10))\n\ndef formatting_prompts_func(example):\n    output_texts = []\n    for i in range(len(example['clean_text'])):\n        messages = [\n            {\"role\": \"user\",\n             \"content\": \"Given the following case, write a short summary of the case in 2-3 sentences:\\n\\nArticle: {}\".format(example['clean_text'][i])},\n            {\"role\": \"assistant\",\n             \"content\": \"{}\".format(example['summary'][i])}\n        ]\n        output_texts.append(tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False))\n        \n    return output_texts\n\n# Print the first training example\nprint(formatting_prompts_func(train_data[:1])[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:58:31.421709Z","iopub.execute_input":"2024-03-29T23:58:31.422456Z","iopub.status.idle":"2024-03-29T23:58:32.552017Z","shell.execute_reply.started":"2024-03-29T23:58:31.422425Z","shell.execute_reply":"2024-03-29T23:58:32.551060Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<start_of_turn>user\nGiven the following case, write a short summary of the case in 2-3 sentences:\n\nArticle: SECTIONHEADER SHORT TITLE. This Act may be cited as the \"Border Hospital Survival and Illegal Immigrant Care Act\". SECTIONHEADER FINDINGS. The Congress finds as follows: Immigration is a Federal responsibility. The Immigration and Naturalization Service does not take into custody all aliens who are unlawfully present in the United States. Section 1867 of the Social Security Act and State laws require that, if any individual comes to a hospital and the hospital determines that the individual has an emergency medical condition, the hospital must provide either, within the staff and facilities available at the hospital, for such further medical examination and such treatment as may be required to stabilize the medical condition, or, if appropriate, for transfer of the individual to another medical facility. The Southwest border region is ill-equipped to absorb the expense of providing health care to undocumented aliens because it ranks last in the country in terms of per capita income. The Southwest border region has been designated as a health professional shortage area under section 332 of the Public Health Service Act . The unreimbursed costs associated with caring for undocumented aliens are severely threatening the financial stability of health care providers in Arizona. SECTIONHEADER REIMBURSEMENT TO HEALTH CARE PROVIDERS FOR EMERGENCY MEDICAL CARE RENDERED TO CERTAIN ALIENS. Section 322 of the Public Health Service Act is amended by adding at the end the following: (1) The Secretary shall establish and implement a 5-year pilot program under which funds made available under paragraph (6) are used to reimburse providers for items and services described in section 411(b)(1) of the Personal Responsibility and Work Opportunity Reconciliation Act of 1996 (8 USC. 1621(b)(1)) provided in Arizona to aliens described in paragraph (3), and to reimburse suppliers of emergency ambulance services furnished to such aliens for which the transportation originates in Arizona , if payment may not be made to reimburse the provider or supplier under any Federal program or law other than this subsection , any State or local program or law, any group or individual health plan, or any insurance policy. As part of the pilot program, in a case in which an alien described in paragraph (3) arrived at a hospital in Arizona and the hospital provided for such medical examination and treatment of the alien as the hospital determined was required to stabilize an emergency medical condition (within the meaning of section 1867(e)(1) of the Social Security Act (42 USC. 1395dd(e)(1))), the Secretary shall use funds made available under paragraph (6) to reimburse the hospital for any transportation costs paid by the hospital to return the alien to the United States border, if the hospital requested the Attorney General to take the alien into custody after such stabilization; such request was denied within 24 hours after its receipt, or the Attorney General gave no response to it within such period; and the hospital determined that discharging the alien without providing for such transportation might pose a threat to the health or safety of the alien . An alien is described in this paragraph if the alien is not lawfully present in the United States and not detained by any Federal, State, or local law enforcement authority; or is paroled into the United States under section 212(d)(5) of the Immigration and Nationality Act (8 USC. 1182(d)(5)) for less than one year in order to receive treatment for an emergency medical condition. During the period in which the pilot program is operating, the Secretary shall submit annual reports to the Congress on its operation. Each report shall contain at least the following information: The number of aliens to whom assistance was rendered for which payment was made under this subsection during the previous year. The nationality of such aliens. The average cost per alien of such assistance. The total annual amount paid to each provider or supplier of assistance. The feasibility and estimated cost of expanding the pilot program to items and services provided anywhere in the Southwest border region of the United States. Nothing in this subsection shall be construed to authorize any reduction in the funds payable to any person under any Federal program or law other than this subsection , any State or local program or law, any group or individual health plan, or any insurance policy. To the extent provided in appropriations Acts, from amounts made available to the Immigration and Naturalization Service for enforcement and border affairs for each of the 5 fiscal years following the fiscal year in which the Border Hospital Survival and Illegal Immigrant Care Act is enacted, the Attorney General may transfer to the Health Resources and Services Administration of the Department of Health and Human Services such amounts as may be necessary to carry out this subsection, not to exceed $50,000,000 for each such year.\".<end_of_turn>\n<start_of_turn>model\nBorder Hospital Survival and Illegal Immigrant Care Act - Amends the Public Health Service Act to direct the Secretary of Health and Human Services to establish a five-year pilot program of health care provider reimbursement for the costs associated with providing emergency medical and ambulance services in Arizona to: (1) illegal aliens who are not detained by any Federal, State, or local law enforcement authority. Or (2) aliens paroled into the United States for less than one year to receive emergency medical treatment.<end_of_turn>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:58:50.128197Z","iopub.execute_input":"2024-03-29T23:58:50.128870Z","iopub.status.idle":"2024-03-29T23:59:05.594330Z","shell.execute_reply.started":"2024-03-29T23:58:50.128839Z","shell.execute_reply":"2024-03-29T23:59:05.593089Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=cdad5329f9fb2c3962b8422b6b9cf59321d5fd14c049c54fb686820f1514207c\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\nimport evaluate\nrouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}\n\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_data,\n    eval_dataset = testing_data,\n    max_seq_length=512,\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=4,\n        warmup_steps=2,\n        max_steps=30,\n        learning_rate=2e-4,\n        fp16=True,\n        logging_steps=1,\n        report_to='none',\n        output_dir='logs',\n        optim=\"paged_adamw_8bit\"\n    ),\n    compute_metrics=compute_metrics,\n    peft_config=lora_config,\n    formatting_func=formatting_prompts_func,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-30T00:00:01.319601Z","iopub.execute_input":"2024-03-30T00:00:01.320364Z","iopub.status.idle":"2024-03-30T00:02:51.056942Z","shell.execute_reply.started":"2024-03-30T00:00:01.320332Z","shell.execute_reply":"2024-03-30T00:02:51.055983Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b6a721cd2244bb9b3726c6bfc754963"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac02784b687649b199b91401a28b3910"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30/30 02:13, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.757300</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.018100</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.726800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.767000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.443500</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.471700</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.247600</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.987600</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.135600</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.041900</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.321900</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.123000</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.162500</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.127600</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.954000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.140400</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.906600</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.679200</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.912000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.149000</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>2.034100</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.920100</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.820400</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.652100</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.680100</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>2.019500</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.976200</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>2.117500</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.905800</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.888800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=30, training_loss=2.1362595240275066, metrics={'train_runtime': 138.791, 'train_samples_per_second': 0.865, 'train_steps_per_second': 0.216, 'total_flos': 733312985333760.0, 'train_loss': 2.1362595240275066, 'epoch': 0.01})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.model.save_pretrained('lora_adapter')\n# trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-03-30T00:07:58.192739Z","iopub.execute_input":"2024-03-30T00:07:58.193142Z","iopub.status.idle":"2024-03-30T00:07:58.293584Z","shell.execute_reply.started":"2024-03-30T00:07:58.193104Z","shell.execute_reply":"2024-03-30T00:07:58.292605Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"base_model_name = \"/kaggle/input/gemma/transformers/2b-it/2\"\nadapter_model_name = \"/kaggle/working/lora_adapter\"\n\nmodel = AutoModelForCausalLM.from_pretrained(base_model_name, device_map='auto', torch_dtype=torch.float16)\nmodel = PeftModel.from_pretrained(model, adapter_model_name, device_map='auto', torch_dtype=torch.float16)\n\n# Merge the adapters into the base model so you can use the model like a normal transformers model\nmodel = model.merge_and_unload()\nmodel.save_pretrained('final_model')\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T00:08:00.655581Z","iopub.execute_input":"2024-03-30T00:08:00.655969Z","iopub.status.idle":"2024-03-30T00:08:20.501447Z","shell.execute_reply.started":"2024-03-30T00:08:00.655939Z","shell.execute_reply":"2024-03-30T00:08:20.500396Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9836739fc05495db6cb4ccd809dc0fe"}},"metadata":{}}]},{"cell_type":"code","source":"model = \"/kaggle/working/final_model\"\n\n# Load the HF pipeline using our newly fine-tuned Gemma 2B\npipe_finetuned = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    model_kwargs={\"torch_dtype\": torch.float16},\n    device_map='auto',\n    max_new_tokens=512\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T00:08:20.503468Z","iopub.execute_input":"2024-03-30T00:08:20.503771Z","iopub.status.idle":"2024-03-30T00:08:23.045209Z","shell.execute_reply.started":"2024-03-30T00:08:20.503745Z","shell.execute_reply":"2024-03-30T00:08:23.044431Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f1398fe307462c813965b4596dc7d3"}},"metadata":{}}]},{"cell_type":"code","source":"text = '''SECTIONHEADER SHORT TITLE. This Act may be cited as the \"National Science Education Tax Incentive for Businesses Act of 2007\". SECTIONHEADER CREDITS FOR CERTAIN CONTRIBUTIONS BENEFITING SCIENCE, TECHNOLOGY, ENGINEERING, AND MATHEMATICS EDUCATION AT THE ELEMENTARY AND SECONDARY SCHOOL LEVEL. In General. Subpart D of part IV of subchapter A of chapter 1 of the Internal Revenue Code of 1986 is amended by adding at the end the following new section: \"Section 45O. CONTRIBUTIONS BENEFITING SCIENCE, TECHNOLOGY, ENGINEERING, AND MATHEMATICS EDUCATION AT THE ELEMENTARY AND SECONDARY SCHOOL LEVEL. In General. For purposes of section 38, the elementary and secondary science, technology, engineering, and mathematics (STEM) contributions credit determined under this section for the taxable year is an amount equal to 100 percent of the qualified STEM contributions of the taxpayer for such taxable year. Qualified STEM Contributions. For purposes of this section, the term `qualified STEM contributions' means STEM school contributions, STEM teacher externship expenses, and STEM teacher training expenses. STEM School Contributions. For purposes of this section In general. The term `STEM school contributions' means STEM property contributions, and STEM service contributions. STEM property contributions. The term `STEM property contributions' means the amount which would (but for subsection ) be allowed as a deduction under section 170 for a charitable contribution of STEM inventory property if the donee is an elementary or secondary school described in section 170(b)(1)(A)(ii), substantially all of the use of the property by the donee is within the United States or within the defense dependents' education system for educational purposes in any of the grades K-12 that are related to the purpose or function of the donee, the original use of the property begins with the donee, the property will fit productively into the donee's education plan, the property is not transferred by the donee in exchange for money, other property, or services, except for shipping, installation and transfer costs, and the donee's use and disposition of the property will be in accordance with the provisions of subparagraphs (B) and (E). The determination of the amount of deduction under section 170 for purposes of this paragraph shall be made as if the limitation under section 170(e)(3)(B) applied to all STEM inventory property. STEM service contributions. The term `STEM service contributions' means the amount paid or incurred during the taxable year for STEM services provided in the United States or in the defense dependents' education system for the exclusive benefit of students at an elementary or secondary school described in section 170(b)(1)(A)(ii) but only if the taxpayer is engaged in the trade or business of providing such services on a commercial basis, and no charge is imposed for providing such services. STEM inventory property. The term `STEM inventory property' means, with respect to any contribution to a school, any property which is described in paragraph (1) or (2) of section 1221(a) with respect to the donor, and which is determined by the school to be needed by the school in providing education in grades K-12 in the areas of science, technology, engineering, or mathematics. STEM services. The term `STEM services' means, with respect to any contribution to a school, any service determined by the school to be needed by the school in providing education in grades K-12 in the areas of science, technology, engineering, or mathematics, including teaching courses of instruction at such school in any such area. Defense dependents' education system. For purposes of this subsection, the term `defense dependents' education system' means the program established and operated under the Defense Dependents' Education Act of 1978 . STEM Teacher Externship Expenses. For purposes of this section In general. The term `STEM teacher externship expenses' means any amount paid or incurred to carry out a STEM externship program of the taxpayer but only to the extent that such amount is attributable to the participation in such program of any eligible STEM teacher, including amounts paid to such a teacher as a stipend while participating in such program. STEM externship program. The term `STEM externship program' means any program established by a taxpayer engaged in a trade or business within an area of science, technology, engineering, or mathematics, and under which eligible STEM teachers receive training to enhance their teaching skills in the areas of science, technology, engineering, or mathematics or otherwise improve their knowledge in such areas. Eligible stem teacher. The term `eligible STEM teacher' means any individual who is a teacher in grades K-12 at an educational organization described in section 170(b)(1)(A)(ii) which is located in the United States or which is located on a United States military base outside the United States, and whose teaching responsibilities at such school include, or are likely to include, any course in the areas of science, technology, engineering, or mathematics. STEM Teacher Training Expenses. The term `STEM teacher training expenses' means any amount paid or incurred by a taxpayer engaged in a trade or business within an area of science, technology, engineering, or mathematics which is attributable to the participation of any eligible STEM teacher in a regular training program provided to employees of the taxpayer which is determined by such teacher's school as enhancing such teacher's teaching skills in the areas of science, technology, engineering, or mathematics. Denial of Double Benefit. No deduction shall be allowed under this chapter for any amount allowed as a credit under this section.\". Conforming Amendments. Section 38(b) of such Code is amended by striking \"plus\" at the end of paragraph (30), by striking the period at the end of paragraph (31), and inserting \", plus\", and by adding at the end the following new paragraph: the elementary and secondary science, technology, engineering, and mathematics (STEM) contributions credit determined under section 45O.\". The table of sections for subpart D of part IV of subchapter A of chapter 1 of such Code is amended by adding at the end the following new item: \"Section 45O. Contributions benefiting science, technology, engineering, and mathematics education at the elementary and secondary school level.\". Effective Date. The amendments made by this section shall apply to taxable years beginning after the date of the enactment of this Act.'''\nprompt = [\n            {\"role\": \"user\",\n             \"content\": \"Given the following case, write a short summary of the case in 2-3 sentences:\\n\\nCase Summary: {}\".format(text)},\n    \n        ]\n\nprompt = pipe_finetuned.tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n\noutputs = pipe_finetuned(\n    prompt,\n    do_sample=True,\n    temperature=0.1,\n    top_k=20,\n    top_p=0.3,\n    add_special_tokens=True\n)\nprint(outputs[0][\"generated_text\"][len(prompt):])","metadata":{"execution":{"iopub.status.busy":"2024-03-30T00:13:17.568588Z","iopub.execute_input":"2024-03-30T00:13:17.568944Z","iopub.status.idle":"2024-03-30T00:13:21.298726Z","shell.execute_reply.started":"2024-03-30T00:13:17.568919Z","shell.execute_reply":"2024-03-30T00:13:21.297678Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Sure, here's a summary of the case in 2-3 sentences:\n\nThe case provides a tax incentive for businesses to contribute to STEM education programs at the elementary and secondary school level. The incentive is a 100 percent tax credit for STEM contributions, which include STEM school contributions, STEM teacher externship expenses, and STEM teacher training expenses.\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"results_1\", 'zip', \"/kaggle/working/final_model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T00:33:18.162475Z","iopub.execute_input":"2024-03-30T00:33:18.163500Z","iopub.status.idle":"2024-03-30T00:38:48.495492Z","shell.execute_reply.started":"2024-03-30T00:33:18.163467Z","shell.execute_reply":"2024-03-30T00:38:48.494589Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/results_1.zip'"},"metadata":{}}]},{"cell_type":"code","source":"from rouge import Rouge\ndef calculate_rouge_score(ref_summ, gen_summ):\n    rouge = Rouge()\n\n    # Calculate ROUGE scores\n    scores = rouge.get_scores(gen_summ, ref_summ)\n\n    # Extract ROUGE-1, ROUGE-2, and ROUGE-L scores\n    rouge_1_score = scores[0][\"rouge-1\"][\"f\"]\n    rouge_2_score = scores[0][\"rouge-2\"][\"f\"]\n    rouge_l_score = scores[0][\"rouge-l\"][\"f\"]\n    return rouge_1_score, rouge_2_score, rouge_l_score\n\ncase = '''SECTIONHEADER RELEASE OF DOCUMENTS CAPTURED IN IRAQ AND AFGHANISTAN. In General. The Director of National Intelligence shall make publicly available on an Internet website all captured documents. Review by Director of National Intelligence. The Director of National Intelligence may review a captured document before making such document publicly available under subsection (a). The Director shall not be required to make a captured document publicly available under subsection (a) if in the case of a captured document that is reviewed by the Director before the date of the enactment of this Act, the Director submits to the relevant congressional committees a description of the criteria the Director used to determine it is not appropriate to make a captured document publicly available and such captured document meets such criteria; or in the case of a captured document that is reviewed by the Director on or after the date of the enactment of this Act, the Director submits to the relevant congressional committees a description of the criteria the Director shall use to determine if it is not appropriate to make a captured document publicly available and the captured document meets such criteria. Submission of Description of Non-Released Documents. Review before date of enactment. Not later than 90 days after the date of the enactment of this Act, the Director of National Intelligence shall submit to the relevant congressional committees a report containing a description of each captured document that, before such date, the Director determined should not be made publicly available; and an explanation as to why the Director does not consider it appropriate to make such captured document publicly available. Review after date of enactment. Not later than 30 days after the Director of National Intelligence determines that a captured document should not be made publicly available pursuant to subsection (b)(2), the Director shall submit to the relevant congressional committees a report containing a description of such captured document and an explanation as to why the Director does not consider it appropriate to make such document publicly available. Request for document. The Director of National Intelligence shall make a copy of each captured document available to the relevant congressional committees for review upon request of the Chairman of any of such relevant congressional committees. The Director shall make such copy available in either classified or unclassified form. Publication or Review Date. In general. The Director of National Intelligence shall begin making captured documents publicly available pursuant to subsection (a) not later than 30 days after the date of the enactment of this Act. Documents collected prior to date of enactment. In general. Not later than the date described in subparagraph (B), for each captured document captured or collected before the date of the enactment of this Act, the Director of National Intelligence shall make such captured document publicly available pursuant to subsection (a) or shall submit to the relevant congressional committees a report regarding such captured document pursuant to subsection (c). Dates. The date described in this subparagraph is September 30, 2006, for captured documents captured or collected during Operation Enduring Freedom and Operation Iraqi Freedom; and March 31, 2007, for captured documents captured or collected during Operation Desert Storm. Documents collected after date of enactment. For each captured document that is captured or collected on or after the date of the enactment of this Act, not later than 60 days after the date on which such captured document is captured or collected, the Director of National Intelligence shall make such captured document publicly available pursuant to subsection (a) or shall submit to the relevant congressional committees a report regarding such captured document pursuant to subsection (c). Weekly Report. Not later than 7 days after the date of enactment of this Act, and weekly thereafter until each captured document captured or collected before the date of the enactment of this Act is made publicly available pursuant to subsection (a) or described in a report submitted pursuant to subsection (c), the Director of National Intelligence shall submit to the relevant congressional committees a report describing the progress in making captured documents publicly available. Definitions. In this section: Captured document. The term \"captured document\" means a document captured or collected in Afghanistan or Iraq, including a document collected from the Government of Iraq or from a private person and including a document in electronic form, during Operation Desert Storm, Operation Enduring Freedom, and Operation Iraqi Freedom. Relevant congressional committees. The term \"relevant congressional committees\" means the Permanent Select Committee on Intelligence of the House of Representatives and Select Committee on Intelligence of the Senate.'''\nsumm = '''Requires the Director of National Intelligence to make publicly available on an Internet website all documents captured in Afghanistan or Iraq during Operations Desert Storm, Enduring Freedom, or Iraqi Freedom. Provides conditions under which the Director shall not be required to make a captured document publicly available, including providing a list of retained documents, and the criteria used for such retention, to the congressional intelligence committees.'''\nprompt = [\n        {\"role\": \"user\",\n         \"content\": \"Given the following case, write a short summary of the case in 2-3 sentences:\\n\\nCase Summary: {}\".format(case)},\n\n    ]\n\nprompt = pipe_finetuned.tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n\noutputs = pipe_finetuned(\n    prompt,\n    do_sample=True,\n    temperature=0.1,\n    top_k=20,\n    top_p=0.3,\n    add_special_tokens=True\n)\ngenerated_summ = outputs[0][\"generated_text\"][len(prompt):]\nprint(\"original_summ:\\n\")\nprint(summ)\nprint(\"generated text:\\n\")\nprint(generated_summ)\nprint(\"\\n\\n\")\nr1,r2,rl = calculate_rouge_score(generated_summ, summ)\nprint(\"r1 : \"+str(r1))\nprint(\"r2 : \"+str(r2))\nprint(\"rL : \"+str(rl))","metadata":{"execution":{"iopub.status.busy":"2024-03-30T01:30:43.541683Z","iopub.execute_input":"2024-03-30T01:30:43.542276Z","iopub.status.idle":"2024-03-30T01:30:46.657432Z","shell.execute_reply.started":"2024-03-30T01:30:43.542246Z","shell.execute_reply":"2024-03-30T01:30:46.656495Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"original_summ:\n\nRequires the Director of National Intelligence to make publicly available on an Internet website all documents captured in Afghanistan or Iraq during Operations Desert Storm, Enduring Freedom, or Iraqi Freedom. Provides conditions under which the Director shall not be required to make a captured document publicly available, including providing a list of retained documents, and the criteria used for such retention, to the congressional intelligence committees.\ngenerated text:\n\nThe case is about the release of captured documents from Iraq and Afghanistan. The Director of National Intelligence has made publicly available all captured documents, but some of the documents have been reviewed by the Director before being made publicly available. The Director has submitted a report to the relevant congressional committees describing the criteria that the Director used to determine which documents should be made publicly available.\n\n\n\nr1 : 0.44444443948576673\nr2 : 0.11290322080775256\nrL : 0.30303029807162535\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
