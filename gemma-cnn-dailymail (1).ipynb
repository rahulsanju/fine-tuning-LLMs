{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566},{"sourceId":11382,"sourceType":"modelInstanceVersion","modelInstanceId":8318}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-29T23:12:09.202118Z","iopub.execute_input":"2024-03-29T23:12:09.203109Z","iopub.status.idle":"2024-03-29T23:12:10.195718Z","shell.execute_reply.started":"2024-03-29T23:12:09.203069Z","shell.execute_reply":"2024-03-29T23:12:10.194710Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/gemma/transformers/2b-it/2/model.safetensors.index.json\n/kaggle/input/gemma/transformers/2b-it/2/gemma-2b-it.gguf\n/kaggle/input/gemma/transformers/2b-it/2/config.json\n/kaggle/input/gemma/transformers/2b-it/2/model-00001-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b-it/2/model-00002-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b-it/2/tokenizer.json\n/kaggle/input/gemma/transformers/2b-it/2/tokenizer_config.json\n/kaggle/input/gemma/transformers/2b-it/2/special_tokens_map.json\n/kaggle/input/gemma/transformers/2b-it/2/.gitattributes\n/kaggle/input/gemma/transformers/2b-it/2/tokenizer.model\n/kaggle/input/gemma/transformers/2b-it/2/generation_config.json\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"training = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv')[['article', 'highlights']]\ntraining.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:12:10.197738Z","iopub.execute_input":"2024-03-29T23:12:10.198649Z","iopub.status.idle":"2024-03-29T23:12:36.868215Z","shell.execute_reply.started":"2024-03-29T23:12:10.198610Z","shell.execute_reply":"2024-03-29T23:12:36.867172Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                             article  \\\n0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n1  (CNN) -- Ralph Mata was an internal affairs li...   \n2  A drunk driver who killed a young woman in a h...   \n3  (CNN) -- With a breezy sweep of his pen Presid...   \n4  Fleetwood are the only team still to have a 10...   \n\n                                          highlights  \n0  Bishop John Folda, of North Dakota, is taking ...  \n1  Criminal complaint: Cop used his role to help ...  \n2  Craig Eccleston-Todd, 27, had drunk at least t...  \n3  Nina dos Santos says Europe must be ready to a...  \n4  Fleetwood top of League One after 2-0 win at S...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article</th>\n      <th>highlights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n      <td>Criminal complaint: Cop used his role to help ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A drunk driver who killed a young woman in a h...</td>\n      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n      <td>Nina dos Santos says Europe must be ready to a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fleetwood are the only team still to have a 10...</td>\n      <td>Fleetwood top of League One after 2-0 win at S...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# !pip install -U -q transformers langchain peft bitsandbytes trl datasets==2.16.0 notebook accelerate evaluate rouge","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:12:36.870723Z","iopub.execute_input":"2024-03-29T23:12:36.871213Z","iopub.status.idle":"2024-03-29T23:12:36.876023Z","shell.execute_reply.started":"2024-03-29T23:12:36.871164Z","shell.execute_reply":"2024-03-29T23:12:36.875056Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline, set_seed\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom accelerate.utils import release_memory\nimport torch\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom datasets import Dataset\nfrom trl import SFTTrainer\nfrom peft import LoraConfig, PeftModel\nimport pandas as pd\nfrom langchain.chains.summarize import load_summarize_chain\nfrom langchain.text_splitter import CharacterTextSplitter, HTMLHeaderTextSplitter\nfrom langchain.prompts import PromptTemplate\nfrom langchain.docstore.document import Document\nfrom langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\nimport evaluate\nimport transformers\nfrom langchain.llms.base import LLM\nfrom typing import Any\nimport warnings\nimport gc\nimport random\nimport numpy as np\n\nwarnings.filterwarnings('ignore')\n\n# Set seed for reproducibility\nset_seed(42)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n# Logging in HF\nlogin(token = 'HF_TOKEN')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:12:36.877466Z","iopub.execute_input":"2024-03-29T23:12:36.878173Z","iopub.status.idle":"2024-03-29T23:12:57.988453Z","shell.execute_reply.started":"2024-03-29T23:12:36.878146Z","shell.execute_reply":"2024-03-29T23:12:57.987392Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-03-29 23:12:44.932494: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-29 23:12:44.932672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-29 23:12:45.069977: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"model = \"/kaggle/input/gemma/transformers/2b-it/2\"\n\nlora_config = LoraConfig(\n    r=6,\n    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    task_type=\"CAUSAL_LM\",\n)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model)\ntokenizer.padding_side = \"right\" # Fixing overflow issue ref: source code\nmodel = AutoModelForCausalLM.from_pretrained(model, device_map=\"auto\", quantization_config=bnb_config)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:12:57.991404Z","iopub.execute_input":"2024-03-29T23:12:57.992372Z","iopub.status.idle":"2024-03-29T23:13:31.780379Z","shell.execute_reply.started":"2024-03-29T23:12:57.992342Z","shell.execute_reply":"2024-03-29T23:13:31.779254Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Gemma's activation function should be approximate GeLU and not exact GeLU.\nChanging the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6614d16b5dab44909e3c5089774fc143"}},"metadata":{}}]},{"cell_type":"code","source":"training = training.head(10000)\ntrain_data = Dataset.from_pandas(training)\n\ntest_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\")[['article', 'highlights']]\ntesting_data = Dataset.from_pandas(test_df.head(10))\n\ndef formatting_prompts_func(example):\n    output_texts = []\n    for i in range(len(example['article'])):\n        messages = [\n            {\"role\": \"user\",\n             \"content\": \"Given the following article, write a short summary of the article in 2-3 sentences:\\n\\nArticle: {}\".format(example['article'][i])},\n            {\"role\": \"assistant\",\n             \"content\": \"{}\".format(example['highlights'][i])}\n        ]\n        output_texts.append(tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False))\n        \n    return output_texts\n\n# Print the first training example\nprint(formatting_prompts_func(train_data[:1])[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:13:31.781587Z","iopub.execute_input":"2024-03-29T23:13:31.781892Z","iopub.status.idle":"2024-03-29T23:13:33.304725Z","shell.execute_reply.started":"2024-03-29T23:13:31.781867Z","shell.execute_reply":"2024-03-29T23:13:33.303671Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<start_of_turn>user\nGiven the following article, write a short summary of the article in 2-3 sentences:\n\nArticle: By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .<end_of_turn>\n<start_of_turn>model\nBishop John Folda, of North Dakota, is taking time off after being diagnosed .\nHe contracted the infection through contaminated food in Italy .\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed .<end_of_turn>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:22:49.005311Z","iopub.execute_input":"2024-03-29T23:22:49.006062Z","iopub.status.idle":"2024-03-29T23:23:05.846614Z","shell.execute_reply.started":"2024-03-29T23:22:49.006030Z","shell.execute_reply":"2024-03-29T23:23:05.844925Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=82bdd79c63f113505f9231ee04b6757e4c6c2de3bfad3d288eca2a3cab2b5b3a\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\nimport evaluate\nrouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}\n\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_data,\n    eval_dataset = testing_data,\n    max_seq_length=512,\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=4,\n        warmup_steps=2,\n        max_steps=30,\n        learning_rate=2e-4,\n        fp16=True,\n        logging_steps=1,\n        report_to='none',\n        output_dir='logs',\n        optim=\"paged_adamw_8bit\"\n    ),\n    compute_metrics=compute_metrics,\n    preprocess_logits_for_metrics = preprocess_logits_for_metrics,\n    peft_config=lora_config,\n    formatting_func=formatting_prompts_func,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:23:05.849292Z","iopub.execute_input":"2024-03-29T23:23:05.849708Z","iopub.status.idle":"2024-03-29T23:25:41.444270Z","shell.execute_reply.started":"2024-03-29T23:23:05.849665Z","shell.execute_reply":"2024-03-29T23:25:41.443189Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9b820e8fbea4bf1bfe085374cd3e4ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5359ebce20cf4a3ca26d92614f428344"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30/30 02:10, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.309200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.647000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.632900</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.800800</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.599600</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.146300</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.905000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.929200</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.114800</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>3.101800</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.905300</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.644000</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.712600</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.632200</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.795100</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.770600</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>2.835000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>2.450200</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>2.689700</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.645500</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>2.656500</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>2.550600</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>2.510200</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>2.553200</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>2.552800</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>2.408700</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>2.662400</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>2.577700</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>2.602900</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.720000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=30, training_loss=2.8687292257944743, metrics={'train_runtime': 135.5696, 'train_samples_per_second': 0.885, 'train_steps_per_second': 0.221, 'total_flos': 711459208052736.0, 'train_loss': 2.8687292257944743, 'epoch': 0.01})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.model.save_pretrained('lora_adapter')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:25:41.445499Z","iopub.execute_input":"2024-03-29T23:25:41.445825Z","iopub.status.idle":"2024-03-29T23:25:41.557601Z","shell.execute_reply.started":"2024-03-29T23:25:41.445798Z","shell.execute_reply":"2024-03-29T23:25:41.556376Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:25:41.560123Z","iopub.execute_input":"2024-03-29T23:25:41.560544Z","iopub.status.idle":"2024-03-29T23:25:48.762737Z","shell.execute_reply.started":"2024-03-29T23:25:41.560510Z","shell.execute_reply":"2024-03-29T23:25:48.761514Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 00:00]\n    </div>\n    "},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 2.6545815467834473,\n 'eval_rouge1': 0.6095,\n 'eval_rouge2': 0.2388,\n 'eval_rougeL': 0.4283,\n 'eval_rougeLsum': 0.4513,\n 'eval_gen_len': 512.0,\n 'eval_runtime': 7.1917,\n 'eval_samples_per_second': 1.39,\n 'eval_steps_per_second': 0.278,\n 'epoch': 0.01}"},"metadata":{}}]},{"cell_type":"code","source":"# Load the pretrained model and our LoRa adapter\nbase_model_name = \"/kaggle/input/gemma/transformers/2b-it/2\"\nadapter_model_name = \"/kaggle/working/lora_adapter\"\n\nmodel = AutoModelForCausalLM.from_pretrained(base_model_name, device_map='auto', torch_dtype=torch.float16)\nmodel = PeftModel.from_pretrained(model, adapter_model_name, device_map='auto', torch_dtype=torch.float16)\n\n# Merge the adapters into the base model so you can use the model like a normal transformers model\nmodel = model.merge_and_unload()\nmodel.save_pretrained('final_model')\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:27:13.549037Z","iopub.execute_input":"2024-03-29T23:27:13.549457Z","iopub.status.idle":"2024-03-29T23:27:35.570155Z","shell.execute_reply.started":"2024-03-29T23:27:13.549426Z","shell.execute_reply":"2024-03-29T23:27:35.569102Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d51754726ca24dee823c4e2caeba278b"}},"metadata":{}}]},{"cell_type":"code","source":"model = \"/kaggle/working/final_model\"\n\n# Load the HF pipeline using our newly fine-tuned Gemma 2B\npipe_finetuned = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    model_kwargs={\"torch_dtype\": torch.float16},\n    device_map='auto',\n    max_new_tokens=512\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:27:35.572064Z","iopub.execute_input":"2024-03-29T23:27:35.572377Z","iopub.status.idle":"2024-03-29T23:27:38.283608Z","shell.execute_reply.started":"2024-03-29T23:27:35.572345Z","shell.execute_reply":"2024-03-29T23:27:38.282596Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5860c42c9c294482af2942bdeef5df2e"}},"metadata":{}}]},{"cell_type":"code","source":"text = \"Sally Forrest, an actress-dancer who graced the silver screen throughout the '40s and '50s in MGM musicals and films such as the 1956 noir While the City Sleeps died on March 15 at her home in Beverly Hills, California. Forrest, whose birth name was Katherine Feeney, was 86 and had long battled cancer. Her publicist, Judith Goffin, announced the news Thursday. Scroll down for video . Actress: Sally Forrest was in the 1951 Ida Lupino-directed film 'Hard, Fast and Beautiful' (left) and the 1956 Fritz Lang movie 'While the City Sleeps' A San Diego native, Forrest became a protege of Hollywood trailblazer Ida Lupino, who cast her in starring roles in films including the critical and commercial success Not Wanted, Never Fear and Hard, Fast and Beautiful. Some of Forrest's other film credits included Bannerline, Son of Sinbad, and Excuse My Dust, according to her iMDB page. The page also indicates Forrest was in multiple Climax! and Rawhide television episodes. Forrest appeared as herself in an episode of The Ed Sullivan Show and three episodes of The Dinah Shore Chevy Show, her iMDB page says. She also starred in a Broadway production of The Seven Year Itch. City News Service reported that other stage credits included As You Like It, No, No, Nanette and Damn Yankees. Forrest married writer-producer Milo Frank in 1951. He died in 2004. She is survived by her niece, Sharon Durham, and nephews, Michael and Mark Feeney. Career: A San Diego native, Forrest became a protege of Hollywood trailblazer Ida Lupino, who cast her in starring roles in films .\"\nprompt = [\n            {\"role\": \"user\",\n             \"content\": \"Given the following article, write a short summary of the article in 20 words:\\n\\nArticle: {}\".format(text)},\n    \n        ]\n\nprompt = pipe_finetuned.tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:27:38.284875Z","iopub.execute_input":"2024-03-29T23:27:38.285213Z","iopub.status.idle":"2024-03-29T23:27:38.299770Z","shell.execute_reply.started":"2024-03-29T23:27:38.285175Z","shell.execute_reply":"2024-03-29T23:27:38.298788Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"outputs = pipe_finetuned(\n    prompt,\n    do_sample=True,\n    temperature=0.1,\n    top_k=20,\n    top_p=0.3,\n    add_special_tokens=True\n)\nprint(outputs[0][\"generated_text\"][len(prompt):])","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:27:38.302184Z","iopub.execute_input":"2024-03-29T23:27:38.302638Z","iopub.status.idle":"2024-03-29T23:27:43.744829Z","shell.execute_reply.started":"2024-03-29T23:27:38.302601Z","shell.execute_reply":"2024-03-29T23:27:43.743775Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Sure, here is a summary of the article in 20 words:\n\nSally Forrest, an actress-dancer, died at 86. She was born Katherine Feeney and became a protege of Ida Lupino. She appeared in several films and television shows, including The Ed Sullivan Show and The Dinah Shore Chevy Show.\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"results_1\", 'zip', \"/kaggle/working/final_model\")\n# !pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:30:16.666414Z","iopub.execute_input":"2024-03-29T23:30:16.667640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from rouge import Rouge\ndef calculate_rouge_score(ref_summ, gen_summ):\n    rouge = Rouge()\n\n    # Calculate ROUGE scores\n    scores = rouge.get_scores(gen_summ, ref_summ)\n\n    # Extract ROUGE-1, ROUGE-2, and ROUGE-L scores\n    rouge_1_score = scores[0][\"rouge-1\"][\"f\"]\n    rouge_2_score = scores[0][\"rouge-2\"][\"f\"]\n    rouge_l_score = scores[0][\"rouge-l\"][\"f\"]\n    return rouge_1_score, rouge_2_score, rouge_l_score\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T22:54:02.894096Z","iopub.execute_input":"2024-03-29T22:54:02.894513Z","iopub.status.idle":"2024-03-29T22:54:02.904710Z","shell.execute_reply.started":"2024-03-29T22:54:02.894478Z","shell.execute_reply":"2024-03-29T22:54:02.903866Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\nclass Node:\n    def __init__(self, article, src_summ, gen_text, r1, r2, rl):\n        self.article = article\n        self.src_summ = src_summ\n        self.gen_text = gen_text\n        self.r1 = r1\n        self.r2 = r2\n        self.rl = rl\n\nrouge_scores = []    \nfor article, summ in test_df.iterrows():\n    prompt = [\n                {\"role\": \"user\",\n                 \"content\": \"Given the following article, write a short summary of the article in 2-3 sentences:\\n\\nArticle: {}\".format(article)},\n\n            ]\n\n    prompt = pipe_finetuned.tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n    outputs = pipe_finetuned(\n                prompt,\n                do_sample=True,\n                temperature=0.1,\n                top_k=20,\n                top_p=0.3,\n                add_special_tokens=True\n                )\n    gen_sum = outputs[0][\"generated_text\"][len(prompt):]\n    r1, r2, rl = calculate_rouge_score(str(summ), gen_sum)\n    rouge_scores.append(Node(article, summ, gen_sum, r1, r2, rl))\n\n    \nrouge_scores\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-29T23:03:56.931201Z","iopub.execute_input":"2024-03-29T23:03:56.931607Z","iopub.status.idle":"2024-03-29T23:07:33.709903Z","shell.execute_reply.started":"2024-03-29T23:03:56.931576Z","shell.execute_reply":"2024-03-29T23:07:33.708672Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
